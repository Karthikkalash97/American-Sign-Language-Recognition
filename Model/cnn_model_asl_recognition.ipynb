{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Sign Language (ASL) Recognition using CNN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a continuation of the American Sign Language (ASL) Recognition project where we have already used a MLP model to detect the gestures but it proved to be inefficient with a validation accuracy of 68.28%(overfitted model) which is not a very favourable score ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### So we will try to build a Convolutional Neural Network model  on the training dataset and compare its accuracy with the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\American Sign Language (ASL) Recognition\\Dataset/train/'\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\American Sign Language (ASL) Recognition\\Dataset/train/'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = os.listdir(paths)\n",
    "print(\"No. of categories of images in the train set = \",len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since this is a supervised learning approach to train the model we will have to label the images before giving it as input to the CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_labels(categories):\n",
    "    img_lst=[]\n",
    "    labels=[]\n",
    "    for index, category in enumerate(categories):\n",
    "        n = 0\n",
    "        for image_name in os.listdir(paths+\"/\"+category):\n",
    "            if n==100:\n",
    "                break\n",
    "                \n",
    "            #load image data into an array\n",
    "            img = cv2.imread(paths+\"/\"+category+\"/\"+image_name)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_array = Image.fromarray(img, 'RGB')\n",
    "            \n",
    "             #resizing the image\n",
    "            resized_img = img_array.resize((200, 200))\n",
    "            \n",
    "            #converting the image array to numpy array before appending it to the list\n",
    "            img_lst.append(np.array(resized_img))\n",
    "            \n",
    "            #appending label\n",
    "            labels.append(index)\n",
    "            \n",
    "            n+=1\n",
    "    return img_lst, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_img_labels(categories)\n",
    "print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the images and labels into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_label_images(images, labels):\n",
    "    plt.figure(1 , figsize = (15 , 10))\n",
    "    n = 0 \n",
    "    for i in range(4):\n",
    "        n += 1 \n",
    "        r = np.random.randint(0 , images.shape[0] , 1)\n",
    "        \n",
    "        plt.subplot(2, 2, n)\n",
    "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.1)\n",
    "        plt.imshow(images[r[0]])\n",
    "        \n",
    "        plt.title('Assigned label : {}'.format(labels[r[0]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "display_label_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating X data and y data using Image augmentation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "imageSize = 64\n",
    "target_dims = (imageSize, imageSize, 3)\n",
    "num_classes = 29\n",
    "train_len = 87000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n",
    "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n",
    "           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(folder):\n",
    "    X = np.empty((train_len, imageSize, imageSize, 3), dtype=np.float32)\n",
    "    y = np.empty((train_len,), dtype=np.int)\n",
    "    i = 0\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith('.'):\n",
    "            for image_filename in os.listdir(folder + folderName):\n",
    "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                    img_arr = np.asarray(img_file).reshape((-1, imageSize, imageSize, 3))\n",
    "                    \n",
    "                    X[i] = img_arr\n",
    "                    y[i] = classes.index(folderName)\n",
    "                    i += 1\n",
    "    return X,y\n",
    "X, y = data_generation(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_data shape : \", X.shape)\n",
    "print(\"y_data shape : \", y.shape)\n",
    "print(\"Image shape : \", X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the X data --> sign language image and the y data --> label of the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2,2,figsize=(8,8))\n",
    "for i in range (0,9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img_nbr = np.random.randint(0,len(X))\n",
    "    plt.imshow(X[img_nbr])\n",
    "    plt.title(classes[y[img_nbr]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing One Hot Encoding on the categorical features of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train,29)\n",
    "y_test_encoded = to_categorical(y_test,29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the dimensions of all variables before they are feeded to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (5, 5), input_shape=(64, 64, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    \n",
    "    Conv2D(64, (3, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(29, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test, y_test_encoded),\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the accuracy and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.loc[0:, ['accuracy','val_accuracy']].plot()\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training accuracy', 'validation accuracy'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the loss and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_df.loc[0:, ['loss', 'val_loss']].plot()\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training loss', 'validation loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training and testing the CNN model we can conclude that it reaches a training accuracy of 99.43% and validation accuracy of 99.78% which shows that the CNN model has gained a very high precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\KIIT\\Documents\\LGM-Soc contributions\\American Sign Language (ASL) Recognition\\Model/sign_language_Recognizer.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing multiclass predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Actual label vs the Predicted label of the Sign Language image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2,2,figsize=(15,15))\n",
    "for i in range (0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img_nbr = np.random.randint(0,len(predictions))\n",
    "    plt.imshow(X[img_nbr])\n",
    "    plt.title(\"True={} ; Predicted={} \".format(classes[(y_test[img_nbr])], classes[(predictions[img_nbr])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(confusion_matrix(y_test,predictions))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
